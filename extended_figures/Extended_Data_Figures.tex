\documentclass{article}

\input{../figure-defs.tex}
\begin{document}

%%%%
%% challenge 1
%%%%
\inclimg{challenge1_src/images/summary-values.pdf}{Extended Data Fig. 0.5.}{
  \warning{Lorem ipsum dolor sit amet, consectetur adipiscing
      elit, sed do eiusmod tempor incididunt ut labore et dolore magna
      aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco
      laboris nisi ut aliquip ex ea commodo consequat.}
}
\inclcrop{challenge1_src/generated/Extended_Fig._23_TMs-coverage-by-tool.pdf}{38pt}{Extended Data Fig. 23.}{
  Percentage of transcript models (TM) with different ranges of sequence
  coverage by long reads. a) WTC11. c) H1-mix. c) Mouse ES. Ba: Bambu, FM: FLAMES, FL: FLAIR,
  IQ: IsoQuant, IT: IsoTools, IB: Iso_IB, Ly: LyRic, Ma: Mandalorion, TL: TALON-LAPA, Sp:
  Spectra, ST: StringTie2.
}
\inclimg{challenge1_src/generated/sirv-cover-cDNA_PacBio.pdf}{Extended Data Fig. 42a.}{
  Positional coverage of SIRV transcript sequences by long reads
  in the cDNA_PacBio sample.
}
\inclimg{challenge1_src/generated/sirv-cover-cDNA_ONT.pdf}{Extended Data Fig. 42c.}{
  Positional coverage of SIRV transcript sequences by long reads
  in the cDNA_ONT sample.
}
\inclcrop{challenge1_src/generated/Extended_Fig._45_gencode-manual-props-wtc11.pdf}{38pt}{Extended Data Fig. 45.}{
  Properties of
  GENCODE manually annotated loci for WTC11 sample.a) Distributon of gene expression. b)
  Distribution of SQANTI categories. c) Intersection of Unique Intron Chains (UIC) among
  experimental protocols.
}
\inclcrop{challenge1_src/generated/Extended_Fig._46_gencode-manual-props-es.pdf}{38pt}{Extended Data Fig. 46.}{
  Properties of GENCODE manually annotated loci for mouse ES sample.a)
  Distributon of gene expression. b) Distribution of SQANTI categories. c) Intersection of
  Unique Intron Chains (UIC) among experimental protocols.
}
%%%%
%% challenge 2
%%%%
\inclimg{challenge2_src/fig_rador_plot.pdf}{Extended Data Fig. 53.}{
  Radar plot of overall evaluation results of eight quantification tools with
  seven protocols-platforms on four data scenarios: real data with multiple
  replicates, cell mixing experiment, SIRV-set 4 data and simulation data. To
  display the evaluation results more effectively, we normalized all metrics
  to 0-1 range: 0 corresponds to the worst performance and 1 corresponds to
  the best performance.
}
\inclcrop{challenge2_src/fig_ranking_on_six_protocols_and_platforms.pdf}{58pt}{Extended Data Fig. 53.1.}{
  Top 3 performance on quantification tools under six different
  protocols-platforms for each metric. Here, quantification tools showcase
  scores under six different protocols-platforms across various evaluation
  metrics, with the top 3 performers highlighted for each metric. Blank spaces
  denote instances where the tool or protocols-platforms did not have
  participants submitting the corresponding quantitative results.
}
%%%%
%% challenge 3
%%%%
\inclcrop{challenge3_src/Extended_Fig._65.pdf}{38pt}{Extended Data Fig. 65.}{
  SQANTI category classification of transcript models detected by the same
  tools in Challenge 1 predictions using the reference
  annotation and Challenge 3 predictions did not. Ba = Bambu, IQ =
  StringTie2/IsoQuant.
}
%%%%
%% validation
%%%%
\inclimg{validation_src/Extended_Data_Fig68_validation_by_supportive_reads.pdf}{Extended Data Fig. 68.}{
  Fraction of experimentally validated WTC-11 transcripts as a function of the total numbers
  of long reads that were observed across the 21 library preparations (e.g.,
  PacBio cDNA, ONT cDNA, PacBio CapTrap).
}
\end{document}
