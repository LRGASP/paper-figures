\documentclass{article}

\input{../figure-defs.tex}
\begin{document}

%%%%
%% challenge 1
%%%%
\inclimg{challenge1_src/images/sqanti3-eval-h1-mix.pdf}{@Extended Data Fig. 1}{
  % was: Extended Data Fig. 2.
  SQANTI3 evaluation of LRGASP submissions of the H1-mix dataset. Labels
  correspond to analysis tools and the color code indicates the combination of
  library preparation and sequencing platform. a) Number of gene and
  transcript detections. b) Number of Full Splice Match and Incomplete Splice
  Match transcripts. c) Number of Novel in Catalogue and Novel Not in
  Catalogue transcripts. d) Number of known and novel transcripts with full
  support at junctions and end positions. e) Percentage of transcripts with
  5´end support. f) Percentage of transcripts with 3´end support. g)
  Percentage of canonical splice junctions (SJ) and short-reads support at SJ.
  Ba: Bambu, FM: Flames, FL: FLAIR, IQ: IsoQuant, IT: IsoTools, IB: Iso_IB,
  Ly: LyRic, Ma: Mandalorion, TL: TALON-LAPA, Sp: Spectra, ST: StringTie2.
}
\inclimg{challenge1_src/images/sqanti3-eval-es.pdf}{@Extended Data Fig. 2}{
  % was: Extended Data Fig. 3.
  SQANTI3 evaluation of LRGASP submissions of the mouse ES dataset. Labels
  correspond to analysis tools and the color code indicates the combination of
  library preparation and sequencing platform. a) Number of gene and
  transcript detections. b) Number of Full Splice Match and Incomplete Splice
  Match transcripts. c) Number of Novel in Catalogue and Novel Not in
  Catalogue transcripts. d) Number of known and novel transcripts with full
  support at junctions and end positions. e) Percentage of transcripts with
  5´end support. f) Percentage of transcripts with 3´end support. g)
  Percentage of canonical splice junctions (SJ) and short-reads support at SJ.
  Ba: Bambu, FM: Flames, FL: FLAIR, IQ: IsoQuant, IT: IsoTools, IB: Iso_IB,
  Ly: LyRic, Ma: Mandalorion, TL: TALON-LAPA, Sp: Spectra, ST: StringTie2.
}
\inclcrop{challenge1_src/generated/Extended_Fig._23_TMs-coverage-by-tool.pdf}{38pt}{@Extended Data Fig. 3}{
  % was: Extended Data Fig. 23.
  Percentage of transcript models (TM) with different ranges of sequence
  coverage by long reads. a) WTC11. c) H1-mix. c) Mouse ES. Ba: Bambu, FM: FLAMES, FL: FLAIR,
  IQ: IsoQuant, IT: IsoTools, IB: Iso_IB, Ly: LyRic, Ma: Mandalorion, TL: TALON-LAPA, Sp:
  Spectra, ST: StringTie2.
}
\inclimg{challenge1_src/generated/sirv-cover-cDNA_PacBio.pdf}{@Extended Data Fig. 4}{
  % was: Extended Data Fig. 42a.
  Positional coverage of SIRV transcript sequences by long reads
  in the cDNA_PacBio sample.
}
\inclcrop{challenge1_src/generated/Extended_Fig._45_gencode-manual-props-wtc11.pdf}{38pt}{@Extended Data Fig. 5}{
  % was: Extended Data Fig. 45.
  Properties of
  GENCODE manually annotated loci for WTC11 sample.a) Distributon of gene expression. b)
  Distribution of SQANTI categories. c) Intersection of Unique Intron Chains (UIC) among
  experimental protocols.
}
\inclcrop{challenge1_src/generated/Extended_Fig._46_gencode-manual-props-es.pdf}{38pt}{@Extended Data Fig. 6}{
  % was: Extended Data Fig. 46.
  Properties of GENCODE manually annotated loci for mouse ES sample.a)
  Distributon of gene expression. b) Distribution of SQANTI categories. c) Intersection of
  Unique Intron Chains (UIC) among experimental protocols.
}
%%%%
%% challenge 2
%%%%
\inclimg{challenge2_src/fig_rador_plot.pdf}{@Extended Data Fig. 7}{
  % was: Extended Data Fig. 53.
  Radar plot of overall evaluation results of eight quantification tools with
  seven protocols-platforms on four data scenarios: real data with multiple
  replicates, cell mixing experiment, SIRV-set 4 data and simulation data. To
  display the evaluation results more effectively, we normalized all metrics
  to 0-1 range: 0 corresponds to the worst performance and 1 corresponds to
  the best performance.
}
\inclcrop{challenge2_src/fig_ranking_on_six_protocols_and_platforms.pdf}{58pt}{@Extended Data Fig. 8}{
  % was: Extended Data Fig. 5300.
  Top 3 performance on quantification tools under six different
  protocols-platforms for each metric. Here, quantification tools showcase
  scores under six different protocols-platforms across various evaluation
  metrics, with the top 3 performers highlighted for each metric. Blank spaces
  denote instances where the tool or protocols-platforms did not have
  participants submitting the corresponding quantitative results.
}
%%%%
%% challenge 3
%%%%
\inclcrop{challenge3_src/Extended_Fig._65.pdf}{38pt}{@Extended Data Fig. 9}{
  % was: Extended Data Fig. 65.
  SQANTI category classification of transcript models detected by the same
  tools in Challenge 1 predictions using the reference
  annotation and Challenge 3 predictions did not. Ba = Bambu, IQ =
  StringTie2/IsoQuant.
}
%%%%
%% validation
%%%%
\inclimg{validation_src/Extended_Data_Fig68_validation_by_supportive_reads.pdf}{@Extended Data Fig. 10}{
  % was: Extended Data Fig. 68.
  Fraction of experimentally validated WTC-11 transcripts as a function of the total numbers
  of long reads that were observed across the 21 library preparations (e.g.,
  PacBio cDNA, ONT cDNA, PacBio CapTrap).
}
\end{document}
